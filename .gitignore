num = 100
fact = 1
while num > 0:
fact = fact * num
num = num - 1
print(fact)

s = ""
for i in range(10):
s += str(i)
print(id(s))
print(s)

character = input("Enter the character from keyboard: ")
unicode = ord(character)
unicode_seq = f'\\u{unicode:04x}'
print("Unicode value of the character is ",unicode_seq)

character = 'à²¤' # character 'T'
unicode = ord(character)
unicode_seq = f'\\u{unicode:04x}'
print("Unicode value of the character is ",unicode_seq)

NLTK
import nltk
from urllib import request
try:
nltk.data.find('tokenizers/punkt')
except nltk.downloader.DownloadError:
nltk.download('punkt')
try:
nltk.data.find('taggers/averaged_perceptron_tagger')
except nltk.downloader.DownloadError:
nltk.download('averaged_perceptron_tagger')
url =
"https://www.gutenberg.org/cache/epub/76571/pg76571.txt"
response = request.urlopen(url)
raw = response.read().decode('utf-8')
# It's a good practice to remove the Project Gutenberg header/footer
# This part is specific to the structure of Project Gutenberg texts
start_of_book = "*** START OF THE PROJECT GUTENBERG EBOOK CRIME AND PUNISHMENT ***"
end_of_book = "*** END OF THE PROJECT GUTENBERG EBOOK CRIME AND PUNISHMENT ***"
# Find the start and end of the actual novel content
start_index = raw.find(start_of_book)
end_index = raw.find(end_of_book)
# Extract the novel content
if start_index != -1 and end_index != -1:
novel_text = raw[start_index + len(start_of_book):end_index].strip()
elif start_index != -1: # If only start marker is found
novel_text = raw[start_index + len(start_of_book):].strip()
else: # If no markers found, use the raw text (less accurate)
novel_text = raw
# Tokenize the novel into sentences
sentences = nltk.sent_tokenize(novel_text)
# Process and print POS tags for each sentence
# For brevity, let's process and print only the first few sentences
print("POS Tags for the first 5 sentences:")
for i, sentence in enumerate(sentences[:5]): # Process only the first 5 sentences
words = nltk.word_tokenize(sentence)
tagged_words = nltk.pos_tag(words)
print(f"Sentence {i+1}: {tagged_words}")
